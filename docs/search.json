[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Studio correlazionala tra SPE ed SE",
    "section": "",
    "text": "In questa prima sezione verranno riportati i passaggi necessari per il calcolo dell’SPE, in particolare:\n\nData cleaning\n\nCalcolo dei tempi di reazione\n\nT-test\n\nVisualizzazione\n\nNella pagina successiva verrà mostrato il procedimento per il calcolo dell’autostima implicita ed esplicita e le correlazioni con SPE. Infine, a pagina tre, si discuteranno brevemente gli esiti statistici."
  },
  {
    "objectID": "index.html#introduzione",
    "href": "index.html#introduzione",
    "title": "Studio correlazionala tra SPE ed SE",
    "section": "",
    "text": "In questa prima sezione verranno riportati i passaggi necessari per il calcolo dell’SPE, in particolare:\n\nData cleaning\n\nCalcolo dei tempi di reazione\n\nT-test\n\nVisualizzazione\n\nNella pagina successiva verrà mostrato il procedimento per il calcolo dell’autostima implicita ed esplicita e le correlazioni con SPE. Infine, a pagina tre, si discuteranno brevemente gli esiti statistici."
  },
  {
    "objectID": "index.html#caricamento-dati-e-visualizzazione",
    "href": "index.html#caricamento-dati-e-visualizzazione",
    "title": "Studio correlazionala tra SPE ed SE",
    "section": "Caricamento dati e visualizzazione",
    "text": "Caricamento dati e visualizzazione\n\nlibrary(readxl)\nlibrary(knitr) # per kable\n\nWarning: il pacchetto 'knitr' è stato creato con R versione 4.4.3\n\nMatching_Task &lt;- read_excel(\"Matching Task.xlsx\")\nkable(head(Matching_Task))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nparticipant_id\ncondizione\ntrial_number\ntrial_type\nlabel\nshape\naccuracy\nRT\n\n\n\n\nABMA\n1\n1\nprctc\nSCONOSCIUTO\nimages/triangle.png\n0\n0.7970\n\n\nABMA\n1\n2\nprctc\nSCONOSCIUTO\nimages/square.png\n0\nNA\n\n\nABMA\n1\n3\nprctc\nTU\nimages/square.png\n1\n0.7699\n\n\nABMA\n1\n4\nprctc\nTU\nimages/triangle.png\n1\n0.8362\n\n\nABMA\n1\n5\nprctc\nTU\nimages/triangle.png\n1\n0.7519\n\n\nABMA\n1\n6\nprctc\nTU\nimages/square.png\n1\n0.4678\n\n\n\n\n\nPer calcolare l’SPE bisonga selezionare solo le risposte corrette (acc=1) ed i trial matching escludendo quelli di pratica (trial_type==“exp”). IMPORTANTE –&gt; tenere conto del numero di condizione relativa al controbilanciamento. Quindi visto come sono organizzati i dati partirei dal creare un secondo df con solo trial_type exp ed acc=1\n\nmatching_df_corr_exp &lt;-Matching_Task[Matching_Task$accuracy == 1 & Matching_Task$trial_type == \"exp\", ]\nkable(head(matching_df_corr_exp))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nparticipant_id\ncondizione\ntrial_number\ntrial_type\nlabel\nshape\naccuracy\nRT\n\n\n\n\nABMA\n1\n21\nexp\nTU\nimages/triangle.png\n1\n0.6827\n\n\nABMA\n1\n22\nexp\nSCONOSCIUTO\nimages/triangle.png\n1\n0.8330\n\n\nABMA\n1\n23\nexp\nTU\nimages/square.png\n1\n0.5678\n\n\nABMA\n1\n24\nexp\nSCONOSCIUTO\nimages/square.png\n1\n0.6984\n\n\nABMA\n1\n25\nexp\nSCONOSCIUTO\nimages/square.png\n1\n0.7102\n\n\nABMA\n1\n26\nexp\nSCONOSCIUTO\nimages/triangle.png\n1\n0.7935\n\n\n\n\n\nadesso si può aggiungere una nuova colonna chiamata: “tipo” che può assumere valore “matching” o “non_matching” matching–&gt; se data condizione 1 shape==images/square.png label==TU e shape==images/triangle.png e label==SCONOSCIUTO per la condizione 2 i matching sono–&gt; shape==images/triangle e label==TU oppure shape==images/square.png e label==SCONOSCIUTO\n\nmatching_df_corr_exp$tipo&lt;-\"non_matching\"\nmatching_df_corr_exp$tipo[matching_df_corr_exp$condizione==1 & (\n(matching_df_corr_exp$shape==\"images/square.png\" &  matching_df_corr_exp$label==\"TU\")|\n(matching_df_corr_exp$shape==\"images/triangle.png\" &  matching_df_corr_exp$label==\"SCONOSCIUTO\")\n)]&lt;-\"matching\"\n\nmatching_df_corr_exp$tipo[matching_df_corr_exp$condizione==2 & (\n  (matching_df_corr_exp$shape==\"images/triangle.png\" &  matching_df_corr_exp$label==\"TU\")|\n    (matching_df_corr_exp$shape==\"images/square.png\" &  matching_df_corr_exp$label==\"SCONOSCIUTO\")\n)]&lt;-\"matching\"\n#ora creiamo df con solo trial matching:\ndf_matching&lt;-matching_df_corr_exp[matching_df_corr_exp$tipo==\"matching\",]\nkable(head(df_matching))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nparticipant_id\ncondizione\ntrial_number\ntrial_type\nlabel\nshape\naccuracy\nRT\ntipo\n\n\n\n\nABMA\n1\n22\nexp\nSCONOSCIUTO\nimages/triangle.png\n1\n0.8330\nmatching\n\n\nABMA\n1\n23\nexp\nTU\nimages/square.png\n1\n0.5678\nmatching\n\n\nABMA\n1\n26\nexp\nSCONOSCIUTO\nimages/triangle.png\n1\n0.7935\nmatching\n\n\nABMA\n1\n27\nexp\nTU\nimages/square.png\n1\n0.4968\nmatching\n\n\nABMA\n1\n30\nexp\nSCONOSCIUTO\nimages/triangle.png\n1\n0.7221\nmatching\n\n\nABMA\n1\n32\nexp\nTU\nimages/square.png\n1\n0.5769\nmatching\n\n\n\n\n\n\n#adesso eliminiamo RT&lt;200ms \ndf_matching &lt;- df_matching[df_matching$RT &gt; 0.2, ]\n#calcoliamo upperlimit individuale: RT &gt;2.5 sd rispetto alla media per singolo participant_id\nmedia_rt&lt;-aggregate(RT ~ participant_id,data = df_matching, FUN = mean)\nsd_rt&lt;-aggregate(RT ~ participant_id,data = df_matching, FUN = sd)\nstat_outliers=merge(media_rt, sd_rt, by = \"participant_id\")\ncolnames(stat_outliers) &lt;- c(\"participant_id\", \"media\", \"sd\")\nstat_outliers$upper_limit&lt;-stat_outliers$media+2.5*stat_outliers$sd\n# eliminiamo RT da df_matching\ndf_matching_limited &lt;- merge(df_matching, stat_outliers, by = \"participant_id\")\ndf_clean_match &lt;- df_matching_limited[df_matching_limited$RT &lt;= df_matching_limited$upper_limit, ]\nView(df_clean_match)\ndf_clean_match$upper_limit &lt;- NULL\n\nAdesso per ciascun partecipante calcoliamo mean RT matching TU e matching SCONOSCIUTO e poi calcoliamo l’SPE\n\nmean_rt_TU&lt;-aggregate(RT ~ participant_id+tipo,data = df_clean_match[df_clean_match$label == \"TU\", ], FUN = mean)\n\ncolnames(mean_rt_TU)&lt;- c(\"participant_id\", \"tipo\", \"media_RT_TU\")\n\nmean_rt_SC&lt;-aggregate(RT ~ participant_id+tipo,data = df_clean_match[df_clean_match$label == \"SCONOSCIUTO\", ], FUN = mean)\n\ncolnames(mean_rt_SC)&lt;- c(\"participant_id\", \"tipo\", \"media_RT_SC\")\nRT_mean_tot&lt;-merge(mean_rt_TU,mean_rt_SC,by = \"participant_id\")\n\nRT_mean_tot$SPE&lt;-RT_mean_tot$media_RT_SC-RT_mean_tot$media_RT_TU\nkable(head(RT_mean_tot))\n\n\n\n\n\n\n\n\n\n\n\n\nparticipant_id\ntipo.x\nmedia_RT_TU\ntipo.y\nmedia_RT_SC\nSPE\n\n\n\n\nABMA\nmatching\n0.5778000\nmatching\n0.7179762\n0.1401762\n\n\nALSC\nmatching\n0.7501667\nmatching\n0.8499796\n0.0998129\n\n\nANGR\nmatching\n0.8839375\nmatching\n0.9263333\n0.0423958\n\n\nCACA\nmatching\n0.6637224\nmatching\n0.7660158\n0.1022933\n\n\nCASC\nmatching\n0.8104898\nmatching\n0.8811128\n0.0706230\n\n\nCHTU\nmatching\n0.7296560\nmatching\n0.9906000\n0.2609440\n\n\n\n\n\n\n## test per valutare la normalità\nshapiro.test(RT_mean_tot$media_RT_TU)\n\n\n    Shapiro-Wilk normality test\n\ndata:  RT_mean_tot$media_RT_TU\nW = 0.94626, p-value = 0.123\n\nshapiro.test(RT_mean_tot$media_RT_SC) #non normali\n\n\n    Shapiro-Wilk normality test\n\ndata:  RT_mean_tot$media_RT_SC\nW = 0.89788, p-value = 0.006384\n\ntest_SPE &lt;-wilcox.test(RT_mean_tot$media_RT_SC, RT_mean_tot$media_RT_TU, paired = TRUE)\n\ntest_SPE\n\n\n    Wilcoxon signed rank exact test\n\ndata:  RT_mean_tot$media_RT_SC and RT_mean_tot$media_RT_TU\nV = 493, p-value = 4.657e-09\nalternative hypothesis: true location shift is not equal to 0\n\n\n\n## Visualizzazione della distribuzione dei tempi di reazione (SPE)\n\nlibrary(ggplot2)\n\nggplot(df_matching, aes(x = RT, fill = label)) +\n  geom_density(alpha = 0.4, color = \"white\", size = 0.3) +\n  labs(\n    title = \"Distribuzione dei tempi di reazione per TU e SCONOSCIUTO (trial matching)\",\n    x = \"RT (s)\",\n    y = \"Densità\"\n  ) +\n  scale_fill_manual(\n    values = c(\"TU\" = \"#00BFC4\", \"SCONOSCIUTO\" = \"#F8766D\"),\n    breaks = c(\"TU\", \"SCONOSCIUTO\"),\n    labels = c(\"TU\", \"SCONOSCIUTO\"),\n    guide = guide_legend(title = NULL)\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    legend.position = \"top\",\n    legend.justification = \"center\",\n    legend.text = element_text(size = 12),\n    panel.grid = element_blank(), \n    plot.title = element_text(hjust = 0.5, face = \"bold\", size = 15),\n    axis.title = element_text(size = 13)\n  )\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\nsaveRDS(RT_mean_tot, file = \"RT_mean_tot.rds\")\n\n→ Vai alla pagina successiva"
  },
  {
    "objectID": "autostima.html",
    "href": "autostima.html",
    "title": "Calcolo Self-Esteem implicita ed esplicita",
    "section": "",
    "text": "In questa sezione vengono descritte le procedure per il calcolo dei punteggi di autostima implicita (IAT, RRT e NLT) e autostima esplicita (RSES). Dopo la pulizia dei dati, calcoleremo le differenze tra blocchi critici nei task impliciti e il punteggio complessivo nella scala di Rosenberg. Infine, eseguiremo le correlazioni tra SPE e le misure di SE."
  },
  {
    "objectID": "autostima.html#introduzione",
    "href": "autostima.html#introduzione",
    "title": "Calcolo Self-Esteem implicita ed esplicita",
    "section": "",
    "text": "In questa sezione vengono descritte le procedure per il calcolo dei punteggi di autostima implicita (IAT, RRT e NLT) e autostima esplicita (RSES). Dopo la pulizia dei dati, calcoleremo le differenze tra blocchi critici nei task impliciti e il punteggio complessivo nella scala di Rosenberg. Infine, eseguiremo le correlazioni tra SPE e le misure di SE."
  },
  {
    "objectID": "autostima.html#caricamento-e-separazione-dei-dati",
    "href": "autostima.html#caricamento-e-separazione-dei-dati",
    "title": "Calcolo Self-Esteem implicita ed esplicita",
    "section": "Caricamento e separazione dei dati",
    "text": "Caricamento e separazione dei dati\n\nRT_mean_tot &lt;- readRDS(\"RT_mean_tot.rds\")\nlibrary(readxl)\nlibrary(knitr)\n\nWarning: il pacchetto 'knitr' è stato creato con R versione 4.4.3\n\nIAT_RRT_NLT_RSES &lt;- read_excel(\"IAT, RRT, NLT, RSES.xlsx\")\ndf_se &lt;- IAT_RRT_NLT_RSES[IAT_RRT_NLT_RSES$trial_type == \"exp\", ]\nkable(head(df_se))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nparticipant_id\ntask\ntrial_type\nblock\naccuracy\nRT\nletter\nitem\nscore\n\n\n\n\nABMA\nIAT\nexp\nblocco1_me_altri\n1\n4.5973\nNA\nNA\nNA\n\n\nABMA\nIAT\nexp\nblocco1_me_altri\n1\n0.9357\nNA\nNA\nNA\n\n\nABMA\nIAT\nexp\nblocco1_me_altri\n1\n1.0440\nNA\nNA\nNA\n\n\nABMA\nIAT\nexp\nblocco1_me_altri\n1\n0.9003\nNA\nNA\nNA\n\n\nABMA\nIAT\nexp\nblocco1_me_altri\n1\n0.7221\nNA\nNA\nNA\n\n\nABMA\nIAT\nexp\nblocco1_me_altri\n1\n0.7505\nNA\nNA\nNA\n\n\n\n\ndf_IAT_RRT &lt;- df_se[df_se$task %in% c(\"IAT\", \"RRT\") & !is.na(df_se$RT), ]\ndf_NLT_RSES &lt;- df_se[df_se$task %in% c(\"NLT\", \"RSES\"), ]"
  },
  {
    "objectID": "autostima.html#pulizia-dati-iat-e-rrt",
    "href": "autostima.html#pulizia-dati-iat-e-rrt",
    "title": "Calcolo Self-Esteem implicita ed esplicita",
    "section": "Pulizia dati: IAT e RRT",
    "text": "Pulizia dati: IAT e RRT\n\ndf_IAT_RRT &lt;- df_IAT_RRT[df_IAT_RRT$RT &gt; 0.2, ]\nblocchi_IAT &lt;- c(\"blocco3_exp\", \"blocco5_exp\")\nblocchi_RRT &lt;- c(\n  \"EXP_blocco_6-7_RRT_lse\",\n  \"EXP_blocco3_4_RRT_hse\",\n  \"EXP_blocco3_4_hse_RRT_2\",\n  \"EXP_blocco_6-7_lse_RRT_2\"\n)\ndf_IAT_RRT_filtrato &lt;- df_IAT_RRT[df_IAT_RRT$block %in% c(blocchi_IAT, blocchi_RRT), ]\n\nmedia_blocchi &lt;- aggregate(RT ~ participant_id + block, data = df_IAT_RRT_filtrato, mean)\nsd_blocchi &lt;- aggregate(RT ~ participant_id + block, data = df_IAT_RRT_filtrato, sd)\nmedia_sd_blocchi &lt;- merge(media_blocchi, sd_blocchi, by = c(\"participant_id\", \"block\"))\ncolnames(media_sd_blocchi) &lt;- c(\"participant_id\", \"block\", \"media\", \"sd\")\nmedia_sd_blocchi$upper_limit &lt;- media_sd_blocchi$media + 2.5 * media_sd_blocchi$sd\n\nmedia_sd_blocchi_small &lt;- media_sd_blocchi[, c(\"participant_id\", \"block\", \"upper_limit\")]\ndf_IAT_RRT_filtrato &lt;- merge(df_IAT_RRT_filtrato, media_sd_blocchi_small, by = c(\"participant_id\", \"block\"))\ndf_IAT_RRT_clean &lt;- df_IAT_RRT_filtrato[df_IAT_RRT_filtrato$RT &lt;= df_IAT_RRT_filtrato$upper_limit, ]\ndf_IAT_RRT_clean &lt;- df_IAT_RRT_clean[, !names(df_IAT_RRT_clean) %in% c(\"upper_limit\", \"score\", \"item\", \"letter\")]\nkable(head(df_IAT_RRT_clean))\n\n\n\n\nparticipant_id\nblock\ntask\ntrial_type\naccuracy\nRT\n\n\n\n\nABMA\nblocco3_exp\nIAT\nexp\n1\n0.7737\n\n\nABMA\nblocco3_exp\nIAT\nexp\n1\n0.5919\n\n\nABMA\nblocco3_exp\nIAT\nexp\n1\n0.5331\n\n\nABMA\nblocco3_exp\nIAT\nexp\n1\n0.6697\n\n\nABMA\nblocco3_exp\nIAT\nexp\n1\n0.5535\n\n\nABMA\nblocco3_exp\nIAT\nexp\n0\n0.4118"
  },
  {
    "objectID": "autostima.html#calcolo-dei-punteggi-se-impliciti-ed-espliciti",
    "href": "autostima.html#calcolo-dei-punteggi-se-impliciti-ed-espliciti",
    "title": "Calcolo Self-Esteem implicita ed esplicita",
    "section": "Calcolo dei punteggi SE impliciti ed espliciti",
    "text": "Calcolo dei punteggi SE impliciti ed espliciti\n\ndf_SE_iat_rrt &lt;- aggregate(RT ~ participant_id + block, data = df_IAT_RRT_clean, mean)\ndf_SE_iat_rrt_wide &lt;- reshape(df_SE_iat_rrt, timevar = \"block\", idvar = \"participant_id\", direction = \"wide\")\ncolnames(df_SE_iat_rrt_wide) &lt;- make.names(colnames(df_SE_iat_rrt_wide))\ndf_SE_iat_rrt_wide$SE_IAT &lt;- df_SE_iat_rrt_wide$RT.blocco3_exp - df_SE_iat_rrt_wide$RT.blocco5_exp\ndf_SE_iat_rrt_wide$SE_RRT_2 &lt;- df_SE_iat_rrt_wide$RT.EXP_blocco_6.7_lse_RRT_2 - df_SE_iat_rrt_wide$RT.EXP_blocco3_4_hse_RRT_2\ndf_SE_iat_rrt_wide$SE_RRT &lt;- df_SE_iat_rrt_wide$RT.EXP_blocco_6.7_RRT_lse - df_SE_iat_rrt_wide$RT.EXP_blocco3_4_RRT_hse\n\n# colonna unica\n\ndf_SE_iat_rrt_wide$SE_RRT_merged &lt;- ifelse(\n  is.na(df_SE_iat_rrt_wide$SE_RRT),\n  df_SE_iat_rrt_wide$SE_RRT_2,\n  df_SE_iat_rrt_wide$SE_RRT\n)\n\n# T-test su SE implicita\n\nt.test(df_SE_iat_rrt_wide$SE_IAT)\n\n\n    One Sample t-test\n\ndata:  df_SE_iat_rrt_wide$SE_IAT\nt = -9.3475, df = 30, p-value = 2.15e-10\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n -0.2064197 -0.1323947\nsample estimates:\n mean of x \n-0.1694072 \n\nt.test(df_SE_iat_rrt_wide$SE_RRT_merged)\n\n\n    One Sample t-test\n\ndata:  df_SE_iat_rrt_wide$SE_RRT_merged\nt = 6.9822, df = 30, p-value = 9.308e-08\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 0.1117816 0.2042075\nsample estimates:\nmean of x \n0.1579946"
  },
  {
    "objectID": "autostima.html#calcolo-se_nlt-e-rses",
    "href": "autostima.html#calcolo-se_nlt-e-rses",
    "title": "Calcolo Self-Esteem implicita ed esplicita",
    "section": "Calcolo SE_NLT e RSES",
    "text": "Calcolo SE_NLT e RSES\n\n# Rimuoviamo colonne non rilevanti\ndf_NLT_RSES &lt;- df_NLT_RSES[, !names(df_NLT_RSES) %in% c(\"block\", \"accuracy\", \"RT\")]\npartecipanti &lt;- toupper(unique(df_NLT_RSES$participant_id))\nse_nlt &lt;- numeric(length(partecipanti))\n\nfor (i in seq_along(partecipanti)) {\n  pid &lt;- partecipanti[i]\n  sub_df &lt;- df_NLT_RSES[toupper(df_NLT_RSES$participant_id) == pid, ]\n  \n  iniziale_nome &lt;- substr(pid, 1, 1)\n  iniziale_cognome &lt;- substr(pid, 3, 3)\n  \n  lettere_presenti &lt;- toupper(sub_df$letter)\n  score_nome &lt;- sub_df$score[lettere_presenti == iniziale_nome]\n  score_cognome &lt;- sub_df$score[lettere_presenti == iniziale_cognome]\n  lettere_da_escludere &lt;- unique(c(iniziale_nome, iniziale_cognome))\n  media_altre &lt;- mean(sub_df$score[!(lettere_presenti %in% lettere_da_escludere)], na.rm = TRUE)\n  \n  if (length(score_nome) &gt; 0 && length(score_cognome) &gt; 0 && !is.na(media_altre)) {\n    media_nome &lt;- mean(score_nome, na.rm = TRUE)\n    media_cognome &lt;- mean(score_cognome, na.rm = TRUE)\n    se_nlt[i] &lt;- ((media_nome - media_altre) + (media_cognome - media_altre)) / 2\n  } else {\n    message(sprintf(\"⚠️ Valori mancanti per %s → nome: %s, cognome: %s\", \n                    pid, toString(score_nome), toString(score_cognome)))\n    se_nlt[i] &lt;- NA\n  }\n}\ndf_se_nlt &lt;- data.frame(participant_id = partecipanti, SE_NLT = round(se_nlt, 2))\nt.test(df_se_nlt$SE_NLT)\n\n\n    One Sample t-test\n\ndata:  df_se_nlt$SE_NLT\nt = 10.105, df = 30, p-value = 3.583e-11\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 2.405285 3.623747\nsample estimates:\nmean of x \n 3.014516 \n\nitem_negativi &lt;- c(\n  \"Sono portato a pensare di essere un vero fallimento\",\n  \"Penso di non avere molto di cui essere fiero\",\n  \"Desidererei aver maggior rispetto di me stesso\",\n  \"Senza dubbio a volte mi sento inutile\",\n  \"A volte penso di essere un buono a nulla\"\n)\ndf_NLT_RSES$score_corretto &lt;- ifelse(\n  df_NLT_RSES$item %in% item_negativi,\n  3 - df_NLT_RSES$score,\n  df_NLT_RSES$score\n)\ndf_rses &lt;- df_NLT_RSES[df_NLT_RSES$task == \"RSES\", ]\ndf_rses_total &lt;- aggregate(score_corretto ~ participant_id, data = df_rses, sum)\ncolnames(df_rses_total) &lt;- c(\"participant_id\", \"RSES_total\")\nmean(df_rses_total$RSES_total)\n\n[1] 20.3871\n\nsd(df_rses_total$RSES_total)\n\n[1] 4.855769"
  },
  {
    "objectID": "autostima.html#correlazioni-tra-spe-e-misure-di-autostima",
    "href": "autostima.html#correlazioni-tra-spe-e-misure-di-autostima",
    "title": "Calcolo Self-Esteem implicita ed esplicita",
    "section": "Correlazioni tra SPE e misure di autostima",
    "text": "Correlazioni tra SPE e misure di autostima\n\ndf_all &lt;- merge(RT_mean_tot[, c(\"participant_id\", \"SPE\")], df_SE_iat_rrt_wide[, c(\"participant_id\", \"SE_IAT\", \"SE_RRT_merged\")], by = \"participant_id\")\ndf_all &lt;- merge(df_all, df_se_nlt, by = \"participant_id\")\ndf_all &lt;- merge(df_all, df_rses_total, by = \"participant_id\")\n\ncor.test(df_all$SPE, df_all$SE_IAT)\n\n\n    Pearson's product-moment correlation\n\ndata:  df_all$SPE and df_all$SE_IAT\nt = -0.12776, df = 27, p-value = 0.8993\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.3875947  0.3450332\nsample estimates:\n       cor \n-0.0245809 \n\ncor.test(df_all$SPE, df_all$SE_RRT_merged)\n\n\n    Pearson's product-moment correlation\n\ndata:  df_all$SPE and df_all$SE_RRT_merged\nt = -0.11764, df = 27, p-value = 0.9072\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.3859377  0.3467486\nsample estimates:\n        cor \n-0.02263347 \n\ncor.test(df_all$SPE, df_all$SE_NLT)\n\n\n    Pearson's product-moment correlation\n\ndata:  df_all$SPE and df_all$SE_NLT\nt = 0.85403, df = 27, p-value = 0.4006\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.2172367  0.4990250\nsample estimates:\n      cor \n0.1621816 \n\ncor.test(df_all$SPE, df_all$RSES_total)\n\n\n    Pearson's product-moment correlation\n\ndata:  df_all$SPE and df_all$RSES_total\nt = -0.51688, df = 27, p-value = 0.6094\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.4491948  0.2775910\nsample estimates:\n        cor \n-0.09898533 \n\ncor.test(df_all$RSES_total, df_all$SE_IAT)\n\n\n    Pearson's product-moment correlation\n\ndata:  df_all$RSES_total and df_all$SE_IAT\nt = -1.0851, df = 27, p-value = 0.2875\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.5311325  0.1752129\nsample estimates:\n       cor \n-0.2044199 \n\ncor.test(df_all$RSES_total, df_all$SE_RRT_merged)\n\n\n    Pearson's product-moment correlation\n\ndata:  df_all$RSES_total and df_all$SE_RRT_merged\nt = 1.6302, df = 27, p-value = 0.1147\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.07543988  0.60001950\nsample estimates:\n      cor \n0.2993424 \n\ncor.test(df_all$RSES_total, df_all$SE_NLT)\n\n\n    Pearson's product-moment correlation\n\ndata:  df_all$RSES_total and df_all$SE_NLT\nt = 0.26777, df = 27, p-value = 0.7909\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.3210975  0.4102326\nsample estimates:\n       cor \n0.05146481 \n\ncor.test(df_all$SE_RRT_merged, df_all$SE_IAT)\n\n\n    Pearson's product-moment correlation\n\ndata:  df_all$SE_RRT_merged and df_all$SE_IAT\nt = -1.3381, df = 27, p-value = 0.192\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.5643126  0.1289015\nsample estimates:\n       cor \n-0.2493859 \n\ncor.test(df_all$SE_NLT, df_all$SE_RRT_merged)\n\n\n    Pearson's product-moment correlation\n\ndata:  df_all$SE_NLT and df_all$SE_RRT_merged\nt = -1.1299, df = 27, p-value = 0.2684\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.5371642  0.1670205\nsample estimates:\n       cor \n-0.2124927 \n\ncor.test(df_all$SE_IAT, df_all$SE_NLT)\n\n\n    Pearson's product-moment correlation\n\ndata:  df_all$SE_IAT and df_all$SE_NLT\nt = -0.85787, df = 27, p-value = 0.3985\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.4995735  0.2165404\nsample estimates:\n      cor \n-0.162893"
  },
  {
    "objectID": "autostima.html#visualizzazione-esempio-correlazione-spe-se_iat",
    "href": "autostima.html#visualizzazione-esempio-correlazione-spe-se_iat",
    "title": "Calcolo Self-Esteem implicita ed esplicita",
    "section": "Visualizzazione esempio: correlazione SPE ~ SE_IAT",
    "text": "Visualizzazione esempio: correlazione SPE ~ SE_IAT\n\nlibrary(ggplot2)\nggplot(df_all, aes(x = SPE, y = SE_IAT)) +\n  geom_point(color = \"#0072B2\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  labs(title = \"Correlazione SPE ~ SE_IAT\", x = \"SPE\", y = \"SE_IAT\") +\n  theme_minimal(base_size = 14)\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "autostima.html#navigazione",
    "href": "autostima.html#navigazione",
    "title": "Calcolo Self-Esteem implicita ed esplicita",
    "section": "Navigazione",
    "text": "Navigazione\n← Torna alla pagina precedente\n→ Vai alla pagina successiva"
  },
  {
    "objectID": "considerazioni.html",
    "href": "considerazioni.html",
    "title": "Discussione dei risultati e analisi di potenza",
    "section": "",
    "text": "Nel presente studio abbiamo replicato l’effetto di self-prioritization (SPE), un effetto ampiamente consolidato in letteratura, evidenziando tempi di reazione significativamente più rapidi per i trial matching associati al Sé rispetto a quelli associati allo sconosciuto. I risultati del t-test confermano che la differenza media tra le condizioni è robusta e statisticamente significativa.\nAnche le misure di autostima esplicita (RSES) e implicita (SE_IAT, SE_RRT, SE_NLT) hanno mostrato distribuzioni coerenti con la letteratura esistente. Tuttavia, le analisi di correlazione non hanno evidenziato associazioni significative tra le misure di self-esteem (esplicite o implicite) e l’SPE, suggerendo che questi costrutti potrebbero avere basi cognitive distinte."
  },
  {
    "objectID": "considerazioni.html#discussione-dei-risultati",
    "href": "considerazioni.html#discussione-dei-risultati",
    "title": "Discussione dei risultati e analisi di potenza",
    "section": "",
    "text": "Nel presente studio abbiamo replicato l’effetto di self-prioritization (SPE), un effetto ampiamente consolidato in letteratura, evidenziando tempi di reazione significativamente più rapidi per i trial matching associati al Sé rispetto a quelli associati allo sconosciuto. I risultati del t-test confermano che la differenza media tra le condizioni è robusta e statisticamente significativa.\nAnche le misure di autostima esplicita (RSES) e implicita (SE_IAT, SE_RRT, SE_NLT) hanno mostrato distribuzioni coerenti con la letteratura esistente. Tuttavia, le analisi di correlazione non hanno evidenziato associazioni significative tra le misure di self-esteem (esplicite o implicite) e l’SPE, suggerendo che questi costrutti potrebbero avere basi cognitive distinte."
  },
  {
    "objectID": "considerazioni.html#analisi-di-potenza-modello-con-4-predittori",
    "href": "considerazioni.html#analisi-di-potenza-modello-con-4-predittori",
    "title": "Discussione dei risultati e analisi di potenza",
    "section": "Analisi di potenza (modello con 4 predittori)",
    "text": "Analisi di potenza (modello con 4 predittori)\nIn questa sezione esploriamo la potenza statistica associata a un modello con quattro predittori, tra cui misure di self-esteem implicito ed esplicito, per prevedere la variabilità individuale nello SPE. Usiamo simulazioni Monte Carlo con parametri realistici derivati dalla letteratura.\n\n# Parametri del modello simulato\nb0 &lt;- 75\nb1 &lt;- 8\nb2 &lt;- 30\nb3 &lt;- 29\nb4 &lt;- 15.5\nsigma2 &lt;- 625\nsd_error &lt;- sqrt(sigma2)\nfam &lt;- gaussian(link = \"identity\")\n\nns &lt;- c(30, 31, 50, 70, 80, 100, 110, 120, 130, 140, 150, 200)\nnsim &lt;- 1000\npower &lt;- numeric(length(ns))\n\nfor (i in seq_along(ns)) {\n  n &lt;- ns[i]\n  pvals_x1 &lt;- numeric(nsim)\n  pvals_x2 &lt;- numeric(nsim)\n  pvals_x3 &lt;- numeric(nsim)\n  pvals_x4 &lt;- numeric(nsim)\n\n  for (j in 1:nsim) {\n    x1 &lt;- rnorm(n, 0, 1)\n    x2 &lt;- rnorm(n, 0.61, 0.29)\n    x3 &lt;- rnorm(n, 0.52, 0.32)\n    x4 &lt;- rnorm(n, 0.1, 0.6)\n\n    lp &lt;- b0 + b1 * x1 + b2 * x2 + b3 * x3 + b4 * x4\n    mu &lt;- fam$linkinv(lp)\n    y &lt;- rnorm(n, mu, sd_error)\n\n    fit &lt;- glm(y ~ x1 + x2 + x3 + x4, family = fam)\n    pvals_x1[j] &lt;- summary(fit)$coefficients[\"x1\", \"Pr(&gt;|t|)\"]\n    pvals_x2[j] &lt;- summary(fit)$coefficients[\"x2\", \"Pr(&gt;|t|)\"]\n    pvals_x3[j] &lt;- summary(fit)$coefficients[\"x3\", \"Pr(&gt;|t|)\"]\n    pvals_x4[j] &lt;- summary(fit)$coefficients[\"x4\", \"Pr(&gt;|t|)\"]\n  }\n\n  power[i] &lt;- mean((pvals_x1 &lt;= 0.05) & (pvals_x2 &lt;= 0.05) & \n                   (pvals_x3 &lt;= 0.05) & (pvals_x4 &lt;= 0.05))\n}\n\n# Salva i risultati in un dataframe\nresult &lt;- data.frame(SampleSize = ns, Power = power)\nresult\n\n   SampleSize Power\n1          30 0.038\n2          31 0.042\n3          50 0.179\n4          70 0.392\n5          80 0.548\n6         100 0.712\n7         110 0.779\n8         120 0.850\n9         130 0.892\n10        140 0.905\n11        150 0.922\n12        200 0.986\n\n# Calcola la potenza esatta per n = 31\nexact_power_31 &lt;- result$Power[result$SampleSize == 31]\nexact_power_31\n\n[1] 0.042\n\n\n\nGrafico della curva di potenza\n\nlibrary(ggplot2)\n\nplot_finale &lt;- ggplot(result, aes(x = SampleSize, y = Power)) +\n  geom_line(size = 0.9, color = \"darkgrey\", linetype = \"dashed\") +\n  geom_point(size = 3, color = \"darkgrey\") +\n  geom_vline(xintercept = 31, linetype = \"dotted\", color = \"red\") +\n  annotate(\"text\", x = 31, y = exact_power_31 + 0.05,\n           label = paste0(\"n = 31\\nPower = \", round(exact_power_31, 2)),\n           color = \"red\", size = 4, hjust = -0.1) +\n  scale_y_continuous(limits = c(0, 1.05), breaks = seq(0, 1, 0.25), expand = c(0, 0)) +\n  scale_x_continuous(breaks = seq(30, 200, by = 20), limits = c(30, 200)) +\n  labs(\n    x = \"Sample size\",\n    y = \"Power\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    plot.title = element_text(face = \"bold\", hjust = 0.5),\n    panel.grid.minor = element_blank(),\n    theme_bw()\n  )\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\nplot_finale\n\n\n\n\n\n\n\n\nCon una dimensione campionaria attuale di n = 31, la probabilità stimata di ottenere effetti statisticamente significativi per tutti e quattro i predittori è pari a 4.2%, secondo le simulazioni Monte Carlo effettuate.\n← Torna alla pagina precedente"
  }
]